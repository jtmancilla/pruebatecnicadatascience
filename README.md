# PRUEBA TCNICA PARA TEAM DE BOOTCAMP DE DATA SCIENCE E IA

隆Hola! Gracias por tu inter茅s en ser parte de nuestro bootcamp de Data Science e Inteligencia Artificial de U Camp. 

A continuaci贸n, te comparto unas preguntas relacionadas a tu 谩rea. Resp贸ndelas de acuerdo a tus conocimientos y experiencia y espero tus respuestas en mi correo nancy.nava@utel.edu.mx a m谩s tardar 3 d铆as naturales despu茅s de haberte enviado esta prueba.



1. 驴Qu茅 t茅cnicas de Machine Learning has implementado?

NLP (natural language processing) para sentiment analysis y categorizaci贸n de contenido por t贸picos. En sentiment analysis utilic茅 SVM (M谩quinas de soporte vectorial), algoritmo de aprendizaje supervisado para categorizar el sentimiento del texto en positivo, negativo o neutral. Y para la categorizaci贸n de contenido por t贸pico he utilizado Naive Bayes y una acercamiento con WordToVec y sentenceToVec en combinaci贸n con Clustering (no supervisado). 

Supervisado:
Para predicci贸n de precios he utilizado Regresi贸n Log铆stica y Lineal.  (El valor de una vivienda con base en sus car谩cteristicas y ubicaci贸n).

Para categorizaci贸n de im谩genes Red Neural con Tensorflow 

Naive Bayes para detecci贸n documentos no deseados.

Metodos ensamblados como Random Forests, GBM , AdaBoost para predicciones deportivas.

No Supervisado:
Clustering para segmentaci贸n de mercado.
Clustering exploraci贸n de informaci贸n.


2. 驴Cu谩les son los pasos para hacer un 谩rbol de decisiones?

Un arbol de decisi贸n nos va a permitir clasificar, recomendar o tomar una decisi贸n con base en ciertos atributos que se van decidiendo conforme avanza el an谩lisis (profundizando). 

Se empieza con una idea principal y se va ramificando seg煤n las consecuencias de las decisiones.

El enfoque com煤n es de arriba hacia abajo, empezando por un nodo raiz o una idea. 
Posteriomente se van agregando nodos conforme se toma una decisi贸n o se tienen nuevos atributos.
Se calculan los valores al tomar una decisi贸n (probabilidad de decidir por uno o por otra rama).
Se evalua los resultados (Entropy o GINI son utilizados para evaluar la ganancia o perdida de informaci贸n conforme se tomaron las decisiones).


3. 驴De qu茅 forma evitas el sobreajuste en los modelos?

Para evitar el sobreajuste podemos probar varias caminos:

- La validaci贸n cruzada, esta es una t茅cnica que nos va a permitir evaluar nuestros modelos dividiendo nuestro conjunto de datos en diferentes subconjuntos que seran evaluados de forma alternada.  
- Podemos probar modelos m谩s simples. Un modelo demasiado cargado puede sobreajustar los resultados, por lo que es importante seleccionar atributos de relevancia y no necesariamente utilizar todo.
- Aumentar el volumen de datos, tener pocos datos nos puede sesgar los resultados, por lo que es conveniente tener una muestra robusta de datos para poder tener mejores resultados y evitar el sobreajuste.
- Parar anticipadamente, al utilizar t茅cnicas de machine learning, buscamos minimizar el error y algunas veces nos topamos con m铆nimos locales, parar antes de sobreajustar un modelo, tambi茅n se puedo probar.


4. 驴C贸mo has evitado que tus modelos arrojen sesgos en los datos?

Primeramente se tiene que realizar un EDA, un an谩lisis exploratorio de los datos, para entender como est谩 distribuida nuestra informaci贸n y que relaciones se presentan. Esto nos va a permitir detectar si existen sesgo en la recolecci贸n o generaci贸n de los datos por cuestiones t茅cnicas o sociales.  Detectar si falt贸 alg煤n atributo o se perdi贸 por alguna raz贸n (limpieza o c贸digo). Detectar si se presenta alg煤n atributo sesjado por alg煤n prejucio (genero, religi贸n, etc) o decisi贸n y balancearlo estad铆sticamente. 

Tambi茅n el sesgo puede evitarse con la validaci贸n cruzada, cuando sistem谩ticamente se elije el mismo conjunto de entrenamiento podemos caer en sesgo, lo mejor es entrenarlo bajo todos los posibles casos.


5. 驴De qu茅 manera determinas que un conjunto de datos es de buena calidad?

Existen criterios que nos permiten evaluar si nuestro datos son de buen calidad o no.
Podemos evaluar la:

- Exactitud (los datos son confiables y precisos. Reflejan la fuente original sin errores o sesgos) 
- Integridad (brindan suficiente informaci贸n)
- Singularidad (no presentan duplicados)
- Disponibilidad (son accesibles)
- Legibilidad ( son entendibles o interpretables)


6. Queremos predecir la probabilidad de muerte por enfermedad card铆aca bas谩ndonos en tres factores de riesgo: edad, sexo y nivel de colesterol en sangre. 驴Cu谩l es el algoritmo m谩s adecuado para este caso y por qu茅?

Podemos utilizar un modelo basado en el teorema de Bayes, facilmente podemos utilizar la probabilidad condicional con base en los tres factores de riesgo para determinar la probilidad de muerte. 


7. Diferencia entre estimaci贸n puntual y el intervalo de confianza

La estimaci贸n puntual es el valor buscado, que regularmente suele ser dificil determinar, por lo que se estiman intervalos de confianza o intervalos de valores que permiten acotar el o los espacios donde puede estar la estimaci贸n puntual. 



8. 驴Qu茅 es una compensaci贸n de sesgo-varianza?

A medida que nuestro modelo busca minimizar el error se calcula una funci贸n de optimizaci贸n (error cuadr谩tico medio o error absoluto), estas funciones van compensando la funci贸n de sesos y funci贸n varianza hasta encontrar el m铆nimo, que es cuando los dos se interceptan y se encuentra la mejor soluci贸n.   


9. 驴A qu茅 desaf铆os te has enfrentado como profesionista dentro del mundo de la Data?

Tener una buena calidad de datos es complicado en el mundo real.  Generalmente nos enfrentamos a modelos que tienen que realizar predicciones con datos mal estructurados o datos sesgados por lo que se tiene que balancear, limpiar y enriquecer con otras fuentes. 

Procesar grandes volumenes de informaci贸n.  Rescientemente analic茅 billones de resitros para detectar ciertos patrones, tuve que utilizar spark, hadoop y parquet para analizar y procesarla. 

Otro reto comun es presentar la informaci贸n.  Todo el trabajo se refleja en una gr谩fica o en tomar una decisi贸n y presentarlo es de suma importacia. 

Revisar y probar el c贸digo y los algoritmos. No es valido asumir que a la primera todo sali贸 sin errores, cuando se programa se van haciendo ajustes y modificando conforme se toman decisiones. Es importante llevar un codigo limpio con un controlador de versiones (git) para poder probar y asegurarnos que realmente hace lo que queremos. 





10. 驴Qu茅 temas consideras que una persona con inter茅s en formarse como Data Scientist deber铆a de tomar?

En general:
Machine Learning, Visual analytics y Manejo de base de datos.

(Inluye: estad铆stica y matem谩ticas, python, postgresql y tableu o powerbi). 


